{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPAMPgOYgvdVcfaHIOuCQ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eth0-02/Astro-Theme-Creek/blob/master/SP_FINAL_SCRIPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FldAgT3V-Anz"
      },
      "outputs": [],
      "source": [
        "# === Colab: Source CSVs -> LONG outputs with EXACT columns (no extras), MonthName, unit-labelled metrics ===\n",
        "!pip -q install pandas numpy\n",
        "\n",
        "import pandas as pd, numpy as np, re, os\n",
        "from calendar import month_abbr\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "OUT_DIR = Path(\"outputs_bi_clean\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ----------------------- helpers -----------------------\n",
        "def _find_timestep_cols(df, base):\n",
        "    \"\"\"Find columns like base_1..base_N (case-insensitive), ordered by index.\"\"\"\n",
        "    pat = re.compile(fr\"^{base}_(\\d+)$\", flags=re.IGNORECASE)\n",
        "    found = []\n",
        "    for c in df.columns:\n",
        "        m = pat.match(c)\n",
        "        if m: found.append((int(m.group(1)), c))\n",
        "    found.sort(key=lambda x: x[0])\n",
        "    return [c for _, c in found]\n",
        "\n",
        "def _month_means(row, cols):\n",
        "    \"\"\"Return 12 monthly means across all years (averaging Jan, Feb, ...).\"\"\"\n",
        "    if not cols:\n",
        "        return pd.Series([np.nan]*12, index=range(1,13))\n",
        "    vals = pd.to_numeric(row[cols], errors=\"coerce\").to_numpy(dtype=\"float64\")\n",
        "    months = (np.arange(vals.size) % 12) + 1\n",
        "    return pd.DataFrame({\"m\": months, \"v\": vals}).groupby(\"m\")[\"v\"].mean().reindex(range(1,13))\n",
        "\n",
        "def _non_timestep_cols(df):\n",
        "    \"\"\"Keep everything except H_#, overflow_#, R_#, balance_#, and MonthNumber/MonthofYear (from source).\"\"\"\n",
        "    step_pat = re.compile(r\"^(H|overflow|R|balance)_\\d+$\", flags=re.IGNORECASE)\n",
        "    drop_src_months = {\"monthnumber\",\"monthofyear\"}\n",
        "    return [c for c in df.columns if not step_pat.match(c) and c.lower() not in drop_src_months]\n",
        "\n",
        "def _choose_level(df, fname):\n",
        "    \"\"\"Detect level by columns then filename: Sub-Basin > Basin > County > Generic.\"\"\"\n",
        "    cols = {c.lower() for c in df.columns}\n",
        "    fn = fname.lower()\n",
        "    if \"sub_hybas_id\" in cols: return \"Sub-Basin\"\n",
        "    if (\"sub\" in fn and \"basin\" in fn) or \"sub-basin\" in fn or \"sub_basin\" in fn: return \"Sub-Basin\"\n",
        "    if \"basin_name\" in cols: return \"Basin\"\n",
        "    if \"basin_hybas_id\" in cols and \"sub_hybas_id\" not in cols: return \"Basin\"\n",
        "    if \"basin\" in fn: return \"Basin\"\n",
        "    if \"county\" in cols or \"county_name\" in cols or \"county\" in fn: return \"County\"\n",
        "    return \"Generic\"\n",
        "\n",
        "def _unify_fid_keep(df):\n",
        "    \"\"\"If both FID and fid exist: keep the one that appears first, fill from the other, drop the duplicate.\"\"\"\n",
        "    if \"FID\" in df.columns and \"fid\" in df.columns:\n",
        "        first_is_FID = list(df.columns).index(\"FID\") < list(df.columns).index(\"fid\")\n",
        "        tgt, src = (\"FID\",\"fid\") if first_is_FID else (\"fid\",\"FID\")\n",
        "        df[tgt] = df[tgt].where(pd.notna(df[tgt]), df[src])\n",
        "        return df.drop(columns=[src])\n",
        "    return df\n",
        "\n",
        "def _id_cols_present(df):\n",
        "    \"\"\"Columns that must never be coerced/filled.\"\"\"\n",
        "    want = {\"hybas_id\",\"sub_hybas_id\",\"basin_hybas_id\",\"fid\",\"adm0_code\"}\n",
        "    return [c for c in df.columns if c.lower() in want]\n",
        "\n",
        "def _metric_fill_spaces_to_zero(df, id_cols):\n",
        "    \"\"\"\n",
        "    Coerce numeric-ish columns & fill NaN/'' -> 0 for metrics only.\n",
        "    Leaves IDs, text/name, geometry, MonthName, Level untouched.\n",
        "    \"\"\"\n",
        "    never = set(id_cols) | {\"MonthName\",\"Level\",\"geometry\"}\n",
        "    def is_text(c): return (\"name\" in c.lower()) or (\"geom\" in c.lower())\n",
        "    for c in df.columns:\n",
        "        if c in never or is_text(c):\n",
        "            continue\n",
        "        s2 = pd.to_numeric(\n",
        "            df[c].astype(str).str.strip().replace({\"\": np.nan, \"None\": np.nan, \"nan\": np.nan}, regex=False),\n",
        "            errors=\"coerce\"\n",
        "        )\n",
        "        if s2.notna().sum()==0 and df[c].dtype==object:\n",
        "            continue\n",
        "        df[c] = s2.fillna(0)\n",
        "    return df\n",
        "\n",
        "def _drop_dup_names(df):\n",
        "    \"\"\"Remove duplicate column names (keep first occurrence).\"\"\"\n",
        "    return df.loc[:, ~pd.Index(df.columns).duplicated(keep=\"first\")]\n",
        "\n",
        "def _unique_outpath(base_dir: Path, base_name: str) -> Path:\n",
        "    \"\"\"Create unique path if file already exists: Name.csv, Name (2).csv, ...\"\"\"\n",
        "    p = base_dir / base_name\n",
        "    if not p.exists(): return p\n",
        "    i = 2\n",
        "    stem, ext = os.path.splitext(base_name)\n",
        "    while True:\n",
        "        q = base_dir / f\"{stem} ({i}){ext}\"\n",
        "        if not q.exists(): return q\n",
        "        i += 1\n",
        "\n",
        "# ----------------------- core transform -----------------------\n",
        "def transform_source_to_long(upload_name: str) -> Path:\n",
        "    src = Path(upload_name)\n",
        "    base = pd.read_csv(src)\n",
        "    base = _unify_fid_keep(base)\n",
        "\n",
        "    # timestep detection and years\n",
        "    Hc = _find_timestep_cols(base, \"H\")\n",
        "    Oc = _find_timestep_cols(base, \"overflow\")\n",
        "    Rc = _find_timestep_cols(base, \"R\")\n",
        "    Bc = _find_timestep_cols(base, \"balance\")\n",
        "    steps = max(len(Hc), len(Oc), len(Rc), len(Bc))\n",
        "    years = int(steps/12) if steps else 0\n",
        "\n",
        "    level = _choose_level(base, src.name)\n",
        "    passthrough = _non_timestep_cols(base)\n",
        "\n",
        "    # build LONG\n",
        "    rows = []\n",
        "    for _, r in base.iterrows():\n",
        "        Hm = _month_means(r, Hc)  # metres\n",
        "        Om = _month_means(r, Oc)  # metres\n",
        "        Rm = _month_means(r, Rc)  # metres\n",
        "        Bm = _month_means(r, Bc)  # metres\n",
        "\n",
        "        # SA for volumes; if missing -> NaN -> filled to 0 later (metrics only)\n",
        "        try: SA_val = float(r.get(\"SA\"))\n",
        "        except: SA_val = np.nan\n",
        "\n",
        "        Om3 = Om * SA_val\n",
        "        Rm3 = Rm * SA_val\n",
        "        Bm3 = Bm * SA_val\n",
        "\n",
        "        for m in range(1, 13):\n",
        "            rec = {\n",
        "                \"Level\": level,\n",
        "                \"YearsAveraged\": years,\n",
        "                \"MonthName\": month_abbr[m],\n",
        "                # unit-labelled monthly means (ONLY additions you requested)\n",
        "                \"H (m)\": Hm.loc[m],\n",
        "                \"R (M3)\": Rm3.loc[m],\n",
        "                \"balance (M3)\": Bm3.loc[m],\n",
        "                \"overflow (M3)\": Om3.loc[m],\n",
        "            }\n",
        "            # pass through all original non-timestep columns EXACTLY as-is\n",
        "            for c in passthrough:\n",
        "                rec[c] = r.get(c, np.nan)\n",
        "            rows.append(rec)\n",
        "\n",
        "    df = pd.DataFrame.from_records(rows)\n",
        "    df = _drop_dup_names(df)\n",
        "    df = _unify_fid_keep(df)\n",
        "\n",
        "    # enforce BASIN_HYBAS_ID rule\n",
        "    if level in {\"County\",\"Basin\"}:\n",
        "        drop = [c for c in df.columns if c.lower()==\"basin_hybas_id\"]\n",
        "        if drop: df = df.drop(columns=drop)\n",
        "\n",
        "    # fill metrics only (IDs/text untouched)\n",
        "    ids = _id_cols_present(df)\n",
        "    df = _metric_fill_spaces_to_zero(df, ids)\n",
        "\n",
        "    # choose output name\n",
        "    if level == \"County\":\n",
        "        out_path = _unique_outpath(OUT_DIR, \"County Output BI.csv\")\n",
        "    elif level == \"Basin\":\n",
        "        out_path = _unique_outpath(OUT_DIR, \"Basin Output BI.csv\")\n",
        "    elif level == \"Sub-Basin\":\n",
        "        out_path = _unique_outpath(OUT_DIR, \"Sub-Basin Output BI.csv\")\n",
        "    else:\n",
        "        out_path = _unique_outpath(OUT_DIR, f\"{src.stem}__Generic Output BI.csv\")\n",
        "\n",
        "    df.to_csv(out_path, index=False)\n",
        "    files.download(str(out_path))\n",
        "    print(f\"[{src.name}] → {out_path.name} | Level: {level} | YearsAveraged: {years}\")\n",
        "    return out_path\n",
        "\n",
        "# ----------------------- optional: quick validation -----------------------\n",
        "def validate_one_id_per_level(source_path: Path, output_path: Path, level_hint: str):\n",
        "    \"\"\"Pick one ID row, recompute monthly means from source, compare with output, and save a diff CSV.\"\"\"\n",
        "    src = pd.read_csv(source_path)\n",
        "    out = pd.read_csv(output_path)\n",
        "\n",
        "    # choose an ID column to match on\n",
        "    for id_col in [\"SUB_HYBAS_ID\",\"HYBAS_ID\",\"BASIN_HYBAS_ID\"]:\n",
        "        if id_col in src.columns and id_col in out.columns:\n",
        "            break\n",
        "    else:\n",
        "        print(f\"[{level_hint}] No common ID column to validate.\")\n",
        "        return\n",
        "\n",
        "    # pick first row with non-null SA (to avoid zero volumes), fallback to first row\n",
        "    if \"SA\" in src.columns and src[\"SA\"].notna().any():\n",
        "        sample_row = src[src[\"SA\"].notna()].iloc[0]\n",
        "    else:\n",
        "        sample_row = src.iloc[0]\n",
        "    sample_id = sample_row[id_col]\n",
        "\n",
        "    # recompute from source\n",
        "    Hc = _find_timestep_cols(src, \"H\")\n",
        "    Oc = _find_timestep_cols(src, \"overflow\")\n",
        "    Rc = _find_timestep_cols(src, \"R\")\n",
        "    Bc = _find_timestep_cols(src, \"balance\")\n",
        "    Hm = _month_means(sample_row, Hc)\n",
        "    Om = _month_means(sample_row, Oc)\n",
        "    Rm = _month_means(sample_row, Rc)\n",
        "    Bm = _month_means(sample_row, Bc)\n",
        "    SA_val = float(sample_row.get(\"SA\")) if \"SA\" in src.columns else np.nan\n",
        "\n",
        "    calc = pd.DataFrame({\n",
        "        \"MonthName\": [month_abbr[m] for m in range(1,13)],\n",
        "        \"H (m) [calc]\": Hm.values,\n",
        "        \"R (M3) [calc]\": (Rm*SA_val).values,\n",
        "        \"balance (M3) [calc]\": (Bm*SA_val).values,\n",
        "        \"overflow (M3) [calc]\": (Om*SA_val).values,\n",
        "    })\n",
        "\n",
        "    out_sel = out[out[id_col]==sample_id][[\"MonthName\",\"H (m)\",\"R (M3)\",\"balance (M3)\",\"overflow (M3)\"]].copy()\n",
        "    merged = pd.merge(calc, out_sel, on=\"MonthName\", how=\"inner\")\n",
        "    for col in [\"H (m)\",\"R (M3)\",\"balance (M3)\",\"overflow (M3)\"]:\n",
        "        merged[f\"{col} diff\"] = merged[f\"{col} [calc]\"] - merged[col]\n",
        "\n",
        "    val_path = OUT_DIR / f\"VALIDATION — {level_hint} — {id_col}={sample_id}.csv\"\n",
        "    merged.to_csv(val_path, index=False)\n",
        "    files.download(str(val_path))\n",
        "    print(f\"[{level_hint}] validation saved:\", val_path.name)\n",
        "\n",
        "# ----------------------- run -----------------------\n",
        "print(\"Upload one or more SOURCE CSVs (e.g., Kenbasin_hydrosheds.csv, Kencounty_hydrosheds.csv, sub_basins_with_basin_attributes.csv)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# transform each uploaded file\n",
        "produced = {}\n",
        "for name in uploaded.keys():\n",
        "    outp = transform_source_to_long(name)\n",
        "    produced[outp.name] = outp\n",
        "\n",
        "# optional: auto-validate one sample per level if we can find a matching source file among uploads\n",
        "# (match by level name in output file)\n",
        "for out_name, out_path in produced.items():\n",
        "    if \"County Output BI\" in out_name:\n",
        "        # try to find a county-like source among uploads\n",
        "        cand = next((k for k in uploaded.keys() if \"county\" in k.lower()), None)\n",
        "        if cand: validate_one_id_per_level(Path(cand), out_path, \"County\")\n",
        "    elif \"Basin Output BI\" in out_name:\n",
        "        cand = next((k for k in uploaded.keys() if \"basin\" in k.lower()), None)\n",
        "        if cand: validate_one_id_per_level(Path(cand), out_path, \"Basin\")\n",
        "    elif \"Sub-Basin Output BI\" in out_name:\n",
        "        cand = next((k for k in uploaded.keys() if \"sub\" in k.lower()), None)\n",
        "        if cand: validate_one_id_per_level(Path(cand), out_path, \"Sub-Basin\")\n",
        "\n",
        "print(\"Done.\")\n"
      ]
    }
  ]
}